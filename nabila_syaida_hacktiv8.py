# -*- coding: utf-8 -*-
"""NABILA SYAIDA HACKTIV8

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gz2K8MQ44lKwDC2IiRWh_Vhp_53MVjZ7
"""



import os
from azure.core.credentials import AzureKeyCredential

# set environment variable dengan nama bebas
os.environ["GITHUB_TOKEN"] = "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"

# ambil dari environment
token = os.environ["GITHUB_TOKEN"]

# buat credential
credential = AzureKeyCredential(token)

print("Credential created:", credential.key)

"""Run this model in Python

> pip install azure-ai-inference
"""
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage
from azure.ai.inference.models import UserMessage
from azure.core.credentials import AzureKeyCredential

# To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.
# Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
client = ChatCompletionsClient(
    endpoint="https://models.github.ai/inference",
    credential=AzureKeyCredential(os.environ["GITHUB_TOKEN"]),
)

response = client.complete(
    messages=[
        UserMessage("Can you explain the basics of machine learning?"),
    ],
    model="deepseek/DeepSeek-R1",
    max_tokens=2048,
)

print(response.choices[0].message.content)

from azure.ai.inference.models import SystemMessage

messages = [
    SystemMessage("You are an expert teacher who explains complex topics clearly and concisely."),
    UserMessage("Explain the basics of machine learning.")
]

UserMessage("Explain machine learning in simple terms with examples and analogies")

history = [
    SystemMessage("You are an AI assistant."),
    UserMessage("Hi!"),
    UserMessage("Can you explain machine learning?")
]
response = client.complete(messages=history, model="deepseek/DeepSeek-R1")

response = client.complete(
    messages=messages,
    model="deepseek/DeepSeek-R1",
    max_tokens=500,
    temperature=0.7
)

output = response.choices[0].message.content.strip()
output = output.replace("\n", " ")

with open("chat_log.txt", "a") as f:
    f.write(f"User: {user_input}\nBot: {output}\n\n")

response = client.complete(
    messages=[
        UserMessage("Can you explain about GENAI?"),
    ],
    model="deepseek/DeepSeek-R1",
    max_tokens=2048,
)

print(response.choices[0].message.content)

response = client.complete(
    messages=[
        UserMessage("Can you explain about HACKTIV8?"),
    ],
    model="deepseek/DeepSeek-R1",
    max_tokens=2048,
)

print(response.choices[0].message.content)



















